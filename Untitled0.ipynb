{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suneethkunche/codes/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEPc53hXXRJ1"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzIuRCudXSrR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Is CUDA available:\", torch.cuda.is_available())\n"
      ],
      "metadata": {
        "id": "BhA4_eUDaoFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model = model.to(device)\n",
        "# data = data.to(device)\n"
      ],
      "metadata": {
        "id": "OdVWhXkaasQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example model setup (replace this with your actual model)\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "model_name = \"bert-base-uncased\"  # Example: Replace with your model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "cgCOWMIytyBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weJNB3Dph50A"
      },
      "outputs": [],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Su9PlK36iA8Y"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0t95URmiBSK"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UL2tAtgiB8X"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clclxAo8iPHh"
      },
      "outputs": [],
      "source": [
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUncdTP4iPcG"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"microsoft/ms_marco\", \"v1.1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8rU6EfdiPtj"
      },
      "outputs": [],
      "source": [
        "documents = ds[\"train\"]\n",
        "print(documents.column_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8En-2dZfi_La"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0jWUKlKipth"
      },
      "outputs": [],
      "source": [
        "load_data = pd.DataFrame(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qG9tC5WjGa2"
      },
      "outputs": [],
      "source": [
        "load_data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lywLHc9DkV4S"
      },
      "outputs": [],
      "source": [
        "print(documents[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_7CPyRSjQdH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from typing import List\n",
        "\n",
        "def rank_passages_tfidf(query: str, passages: List[str]) -> List[int]:\n",
        "    \"\"\"Rank passages by cosine similarity with the query using TF-IDF vectors.\"\"\"\n",
        "    tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "\n",
        "    # Fit TF-IDF on passages and transform query\n",
        "    passage_tfidf_matrix = tfidf_vectorizer.fit_transform(passages)\n",
        "    query_tfidf = tfidf_vectorizer.transform([query])\n",
        "\n",
        "    # Compute cosine similarity between query and all passages\n",
        "    similarity_scores = cosine_similarity(query_tfidf, passage_tfidf_matrix).flatten()\n",
        "\n",
        "    # Rank passages by similarity score\n",
        "    ranked_indices = np.argsort(similarity_scores)[::-1]\n",
        "    return ranked_indices.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1O1pNyNnjgu5"
      },
      "outputs": [],
      "source": [
        "# Sample query and passages\n",
        "query = \"What is Risk-based authentication  ?\"\n",
        "passages = [\n",
        "    \"Results-Based AccountabilityÂ® (also known as RBA) is a disciplined way of thinking and taking action that communities can use to improve the lives of children, youth, families, adults and the community as a whole.\",\n",
        "    \"The Reserve Bank of Australia (RBA) came into being on 14 January 1960 as Australia's central bank and banknote issuing authority.\",\n",
        "    \"RBA uses a data-driven, decision-making process to help communities and organizations get beyond talking about problems to taking action to solve problems.\",\n",
        "    \"A rebuildable atomizer (RBA), often referred to as simply a 'rebuildable,' is a special type of atomizer used in the Vape Pen and Mod Industry.\",\n",
        "    \"Risk-based authentication (RBA) is a method of applying varying levels of stringency to authentication processes.\"\n",
        "]\n",
        "\n",
        "# Call the function to rank passages\n",
        "ranked_indices = rank_passages_tfidf(query, passages)\n",
        "\n",
        "# Display ranked passages\n",
        "print(\"Ranked Passages:\")\n",
        "for idx in ranked_indices:\n",
        "    print(f\"{idx}: {passages[idx]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIfiu7BIj5IP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbvmAvrzj5iR"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x0W731W6GXM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from typing import List\n",
        "\n",
        "def rank_passages_bert(query: str, passages: List[str]) -> List[int]:\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "\n",
        "    def mean_pooling(model_output, attention_mask):\n",
        "        token_embeddings = model_output.last_hidden_state  # (batch_size, seq_len, hidden_size)\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size())\n",
        "        return torch.sum(token_embeddings * input_mask_expanded, dim=1) / input_mask_expanded.sum(dim=1)\n",
        "\n",
        "\n",
        "    query_tokens = tokenizer(query, return_tensors='pt', padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        query_output = model(**query_tokens)\n",
        "        query_embedding = mean_pooling(query_output, query_tokens['attention_mask'])\n",
        "\n",
        "\n",
        "    passage_embeddings = []\n",
        "    for passage in passages:\n",
        "        passage_tokens = tokenizer(passage, return_tensors='pt', padding=True, truncation=True)\n",
        "        with torch.no_grad():\n",
        "            passage_output = model(**passage_tokens)\n",
        "            passage_embedding = mean_pooling(passage_output, passage_tokens['attention_mask'])\n",
        "        passage_embeddings.append(passage_embedding)\n",
        "\n",
        "\n",
        "    passage_embeddings = torch.cat(passage_embeddings, dim=0)\n",
        "\n",
        "\n",
        "    similarity_scores = cosine_similarity(query_embedding.numpy(), passage_embeddings.numpy()).flatten()\n",
        "\n",
        "\n",
        "    ranked_indices = similarity_scores.argsort()[::-1]\n",
        "    return ranked_indices.tolist()\n",
        "\n",
        "query = \"What is  data-driven?\"\n",
        "passages = [\n",
        "    \"Results-Based AccountabilityÂ® (also known as RBA) is a disciplined way of thinking and taking action that communities can use to improve the lives of children, youth, families, adults and the community as a whole.\",\n",
        "    \"The Reserve Bank of Australia (RBA) came into being on 14 January 1960 as Australia's central bank and banknote issuing authority.\",\n",
        "    \"RBA uses a data-driven, decision-making process to help communities and organizations get beyond talking about problems to taking action to solve problems.\",\n",
        "    \"A rebuildable atomizer (RBA), often referred to as simply a 'rebuildable,' is a special type of atomizer used in the Vape Pen and Mod Industry.\",\n",
        "    \"Risk-based authentication (RBA) is a method of applying varying levels of stringency to authentication processes.\"\n",
        "]\n",
        "\n",
        "\n",
        "ranked_indices = rank_passages_bert(query, passages)\n",
        "\n",
        "print(\"Ranked Passages:\")\n",
        "for idx in ranked_indices:\n",
        "    print(f\"{idx}: {passages[idx]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6fK56Jg6Gul"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.covariance import EmpiricalCovariance\n",
        "from scipy.spatial.distance import mahalanobis\n",
        "from typing import List\n",
        "\n",
        "def rank_passages_bert_mahalanobis(query: str, passages: List[str]) -> List[int]:\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def mean_pooling(model_output, attention_mask):\n",
        "        token_embeddings = model_output.last_hidden_state  # (batch_size, seq_len, hidden_size)\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size())\n",
        "        return torch.sum(token_embeddings * input_mask_expanded, dim=1) / input_mask_expanded.sum(dim=1)\n",
        "\n",
        "    # Encode query\n",
        "    query_tokens = tokenizer(query, return_tensors='pt', padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        query_output = model(**query_tokens)\n",
        "        query_embedding = mean_pooling(query_output, query_tokens['attention_mask'])\n",
        "\n",
        "    # Encode passages\n",
        "    passage_embeddings = []\n",
        "    for passage in passages:\n",
        "        passage_tokens = tokenizer(passage, return_tensors='pt', padding=True, truncation=True)\n",
        "        with torch.no_grad():\n",
        "            passage_output = model(**passage_tokens)\n",
        "            passage_embedding = mean_pooling(passage_output, passage_tokens['attention_mask'])\n",
        "        passage_embeddings.append(passage_embedding)\n",
        "\n",
        "    passage_embeddings = torch.cat(passage_embeddings, dim=0).numpy()\n",
        "\n",
        "    # Calculate covariance matrix and its inverse\n",
        "    cov_estimator = EmpiricalCovariance()\n",
        "    cov_estimator.fit(passage_embeddings)\n",
        "    cov_matrix_inv = cov_estimator.precision_\n",
        "\n",
        "    # Calculate Mahalanobis distances\n",
        "    query_embedding_np = query_embedding.numpy().flatten()\n",
        "    distances = [\n",
        "        mahalanobis(query_embedding_np, passage_embedding, cov_matrix_inv)\n",
        "        for passage_embedding in passage_embeddings\n",
        "    ]\n",
        "\n",
        "    # Rank indices based on distances\n",
        "    ranked_indices = sorted(range(len(distances)), key=lambda i: distances[i])\n",
        "    return ranked_indices\n",
        "\n",
        "\n",
        "query = \"What is  atomizer?\"\n",
        "passages = [\n",
        "    \"Results-Based AccountabilityÂ® (also known as RBA) is a disciplined way of thinking and taking action that communities can use to improve the lives of children, youth, families, adults and the community as a whole.\",\n",
        "    \"The Reserve Bank of Australia (RBA) came into being on 14 January 1960 as Australia's central bank and banknote issuing authority.\",\n",
        "    \"RBA uses a data-driven, decision-making process to help communities and organizations get beyond talking about problems to taking action to solve problems.\",\n",
        "    \"A rebuildable atomizer (RBA), often referred to as simply a 'rebuildable,' is a special type of atomizer used in the Vape Pen and Mod Industry.\",\n",
        "    \"Risk-based authentication (RBA) is a method of applying varying levels of stringency to authentication processes.\"\n",
        "]\n",
        "\n",
        "\n",
        "ranked_indices = rank_passages_bert_mahalanobis(query, passages)\n",
        "\n",
        "print(\"Ranked Passages:\")\n",
        "for idx in ranked_indices:\n",
        "    print(f\"{idx}: {passages[idx]}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GkfxPvtueHs"
      },
      "outputs": [],
      "source": [
        "import json  # Import JSON module for parsing passages\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.covariance import EmpiricalCovariance\n",
        "from scipy.spatial.distance import mahalanobis\n",
        "from typing import List\n",
        "from datasets import load_dataset\n",
        "\n",
        "def rank_passages_bert_mahalanobis(query: str, passages: List[str]) -> List[int]:\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def mean_pooling(model_output, attention_mask):\n",
        "        token_embeddings = model_output.last_hidden_state  # (batch_size, seq_len, hidden_size)\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size())\n",
        "        return torch.sum(token_embeddings * input_mask_expanded, dim=1) / input_mask_expanded.sum(dim=1)\n",
        "\n",
        "    # Encode query\n",
        "    query_tokens = tokenizer(query, return_tensors='pt', padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        query_output = model(**query_tokens)\n",
        "        query_embedding = mean_pooling(query_output, query_tokens['attention_mask'])\n",
        "\n",
        "    # Encode passages\n",
        "    passage_embeddings = []\n",
        "    for passage in passages:\n",
        "        passage_tokens = tokenizer(passage, return_tensors='pt', padding=True, truncation=True)\n",
        "        with torch.no_grad():\n",
        "            passage_output = model(**passage_tokens)\n",
        "            passage_embedding = mean_pooling(passage_output, passage_tokens['attention_mask'])\n",
        "        passage_embeddings.append(passage_embedding)\n",
        "\n",
        "    passage_embeddings = torch.cat(passage_embeddings, dim=0).numpy()\n",
        "\n",
        "    # Calculate covariance matrix and its inverse\n",
        "    cov_estimator = EmpiricalCovariance()\n",
        "    cov_estimator.fit(passage_embeddings)\n",
        "    cov_matrix_inv = cov_estimator.precision_\n",
        "\n",
        "    # Calculate Mahalanobis distances\n",
        "    query_embedding_np = query_embedding.numpy().flatten()\n",
        "    distances = [\n",
        "        mahalanobis(query_embedding_np, passage_embedding, cov_matrix_inv)\n",
        "        for passage_embedding in passage_embeddings\n",
        "    ]\n",
        "\n",
        "    # Rank indices based on distances\n",
        "    ranked_indices = sorted(range(len(distances)), key=lambda i: distances[i])\n",
        "    return ranked_indices\n",
        "\n",
        "# Load dataset\n",
        "ds = load_dataset(\"microsoft/ms_marco\", \"v1.1\")\n",
        "documents = ds[\"train\"]\n",
        "\n",
        "# Inspect structure of a single document\n",
        "print(documents.column_names)\n",
        "print(documents[0])\n",
        "\n",
        "# Use a single query and its corresponding passages from the dataset\n",
        "sample_query = documents[1][\"query\"]\n",
        "\n",
        "# Extract passage texts\n",
        "raw_passages = documents[1][\"passages\"]\n",
        "sample_passages = raw_passages[\"passage_text\"]  # Access the list of passages directly\n",
        "\n",
        "# Rank passages for the sample query\n",
        "ranked_indices = rank_passages_bert_mahalanobis(sample_query, sample_passages)\n",
        "\n",
        "# Print ranked passages\n",
        "print(\"Query:\", sample_query)\n",
        "print(\"Ranked Passages:\")\n",
        "for idx in ranked_indices:\n",
        "    print(f\"{idx}: {sample_passages[idx]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqx1L7PpQhVx"
      },
      "outputs": [],
      "source": [
        "###Evaluation\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "\n",
        "def evaluate_metrics(df: pd.DataFrame, relevance_col: str, rank_col: str, k: int = 3):\n",
        "    \"\"\"\n",
        "    Function to calculate\n",
        "        - MRR (Mean Reciprocal Rank)\n",
        "        - nDCG (Normalized Discounted Cumulative Gain)\n",
        "        - Precision@k\n",
        "        - Recall@k\n",
        "        - MAP (Mean Average Precision)\n",
        "    \"\"\"\n",
        "    mrr_scores = []\n",
        "    ndcg_scores = []\n",
        "    precision_at_k = []\n",
        "    recall_at_k = []\n",
        "    average_precisions = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        relevance = np.array(row[relevance_col])  # Convert relevance list to numpy array\n",
        "        rank = np.array(row[rank_col])  # Ranked indices\n",
        "        relevance_at_rank = relevance[rank]\n",
        "\n",
        "        # MRR: Find the rank of the first relevant document\n",
        "        first_relevant = np.where(relevance_at_rank == 1)[0]\n",
        "        if len(first_relevant) > 0:\n",
        "            mrr_scores.append(1 / (first_relevant[0] + 1))\n",
        "        else:\n",
        "            mrr_scores.append(0)\n",
        "\n",
        "        # nDCG\n",
        "        dcg = sum((2 ** relevance_at_rank[i] - 1) / np.log2(i + 2) for i in range(len(relevance_at_rank)))\n",
        "        ideal_relevance = sorted(relevance, reverse=True)\n",
        "        idcg = sum((2 ** ideal_relevance[i] - 1) / np.log2(i + 2) for i in range(len(ideal_relevance)))\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0\n",
        "        ndcg_scores.append(ndcg)\n",
        "\n",
        "        # Top-k relevance\n",
        "        relevance_at_k = relevance_at_rank[:k]\n",
        "\n",
        "        # Precision@k\n",
        "        precision = relevance_at_k.sum() / k\n",
        "        precision_at_k.append(precision)\n",
        "\n",
        "        # Recall@k\n",
        "        total_relevant = relevance.sum()\n",
        "        recall = relevance_at_k.sum() / total_relevant if total_relevant > 0 else 0\n",
        "        recall_at_k.append(recall)\n",
        "\n",
        "        # Average Precision (AP)\n",
        "        num_relevant_retrieved = 0\n",
        "        cumulative_precision = 0\n",
        "        for i in range(len(relevance_at_rank)):\n",
        "            if relevance_at_rank[i] == 1:\n",
        "                num_relevant_retrieved += 1\n",
        "                cumulative_precision += num_relevant_retrieved / (i + 1)\n",
        "        ap = cumulative_precision / total_relevant if total_relevant > 0 else 0\n",
        "        average_precisions.append(ap)\n",
        "\n",
        "    # Aggregate results\n",
        "    metrics = {\n",
        "        \"MRR\": np.mean(mrr_scores),\n",
        "        \"nDCG\": np.mean(ndcg_scores),\n",
        "        f\"Precision at {k}\": np.mean(precision_at_k),\n",
        "        f\"Recall at {k}\": np.mean(recall_at_k),\n",
        "        \"MAP\": np.mean(average_precisions),\n",
        "    }\n",
        "\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQ9oeHmNRakl"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1ygFn5rQmla"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "ds = load_dataset(\"microsoft/ms_marco\", \"v1.1\")\n",
        "\n",
        "# Convert the validation split to a pandas DataFrame\n",
        "df = ds['validation'].to_pandas()\n",
        "# Extract the passage text and is_selected fields\n",
        "df[\"passage_text\"] = df[\"passages\"].apply(lambda x: x[\"passage_text\"].tolist())  # Convert NumPy array to list\n",
        "df[\"is_selected\"] = df[\"passages\"].apply(lambda x: x[\"is_selected\"].tolist())    # Convert NumPy array to list\n",
        "\n",
        "\n",
        "\n",
        "# Extract passage text and selection status\n",
        "# df[\"passage_text\"] = df[\"passages\"].apply(lambda x: x[\"passage_text\"])\n",
        "# df[\"passage_text\"] = df[\"passage_text\"].apply(lambda x: x.split(\". \") if isinstance(x, str) else x)\n",
        "# df[\"is_selected\"] = df[\"passages\"].apply(lambda x: x[\"is_selected\"])\n",
        "\n",
        "# Drop the original passages column and set query_id as index\n",
        "df.drop(\"passages\", axis=1, inplace=True)\n",
        "df.set_index(\"query_id\", inplace=True)\n",
        "\n",
        "# Display the first few rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wJq8JEJQmfb"
      },
      "outputs": [],
      "source": [
        "ranked_indices_bert = rank_passages_bert(df.iloc[0][\"query\"], df.iloc[0][\"passage_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nsDALGNdsv1"
      },
      "outputs": [],
      "source": [
        "print(\"Ranked Indices of bert with cosine:\", ranked_indices_bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnUieP48d5L3"
      },
      "outputs": [],
      "source": [
        "df[\"rank_passages_bert\"] = df.apply(lambda x: rank_passages_bert(x[\"query\"], x[\"passage_text\"]), axis=1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PS2nMC2xeCwY"
      },
      "outputs": [],
      "source": [
        "\n",
        "result1 = evaluate_metrics(df, relevance_col='is_selected', rank_col='rank_passages_bert')\n",
        "result1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PthPQOC_egzu"
      },
      "source": [
        "#model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gT-iuYpeDFt"
      },
      "outputs": [],
      "source": [
        "ranked_indices_bert_mahalanobis = rank_passages_bert_mahalanobis(df.iloc[0][\"query\"], df.iloc[0][\"passage_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGQOT_N7eDgC"
      },
      "outputs": [],
      "source": [
        "print(\"Ranked Indices of bert with mahalanobis:\", ranked_indices_bert_mahalanobis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18HZg-tFec4K"
      },
      "outputs": [],
      "source": [
        "df[\"rank_passages_bert_mahalanobis\"] = df.apply(lambda x: rank_passages_bert_mahalanobis(x[\"query\"], x[\"passage_text\"]), axis=1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmfD1NQYeewv"
      },
      "outputs": [],
      "source": [
        "result2 = evaluate_metrics(df, relevance_col='is_selected', rank_col='rank_passages_bert_mahalanobis')\n",
        "result2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 3\n"
      ],
      "metadata": {
        "id": "2gTHvhig_wfL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yp7AytZTf3h3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from typing import List\n",
        "\n",
        "def rank_passages_bert_dot(query: str, passages: List[str]) -> List[int]:\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def mean_pooling(model_output, attention_mask):\n",
        "        token_embeddings = model_output.last_hidden_state  # (batch_size, seq_len, hidden_size)\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size())\n",
        "        return torch.sum(token_embeddings * input_mask_expanded, dim=1) / input_mask_expanded.sum(dim=1)\n",
        "\n",
        "    # Process the query\n",
        "    query_tokens = tokenizer(query, return_tensors='pt', padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        query_output = model(**query_tokens)\n",
        "        query_embedding = mean_pooling(query_output, query_tokens['attention_mask'])\n",
        "\n",
        "    # Process the passages\n",
        "    passage_embeddings = []\n",
        "    for passage in passages:\n",
        "        passage_tokens = tokenizer(passage, return_tensors='pt', padding=True, truncation=True)\n",
        "        with torch.no_grad():\n",
        "            passage_output = model(**passage_tokens)\n",
        "            passage_embedding = mean_pooling(passage_output, passage_tokens['attention_mask'])\n",
        "        passage_embeddings.append(passage_embedding)\n",
        "\n",
        "    # Concatenate passage embeddings\n",
        "    passage_embeddings = torch.cat(passage_embeddings, dim=0)\n",
        "\n",
        "    # Use dot product scoring instead of cosine similarity\n",
        "    similarity_scores = torch.mm(query_embedding, passage_embeddings.T).squeeze()\n",
        "\n",
        "    # Get ranked indices\n",
        "    ranked_indices = torch.argsort(similarity_scores, descending=True).tolist()\n",
        "    return ranked_indices\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ranked_indices_bert_dot = rank_passages_bert_dot(df.iloc[0][\"query\"], df.iloc[0][\"passage_text\"])"
      ],
      "metadata": {
        "id": "_UzHo4y1_4Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Ranked Indices of bert with dot:\", ranked_indices_bert_dot)"
      ],
      "metadata": {
        "id": "GmrGFYA5_4wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"rank_passages_bert_dot\"] = df.apply(lambda x: rank_passages_bert_dot(x[\"query\"], x[\"passage_text\"]), axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "pefgMRBXANFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result3 = evaluate_metrics(df, relevance_col='is_selected', rank_col='rank_passages_bert_dot')\n",
        "result3"
      ],
      "metadata": {
        "id": "mZriY8PyATti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model 4"
      ],
      "metadata": {
        "id": "0MPqN8iGA1Lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import numpy as np\n",
        "from typing import List\n",
        "\n",
        "def rank_passages_bert_Euclidean(query: str, passages: List[str]) -> List[int]:\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def mean_pooling(model_output, attention_mask):\n",
        "        token_embeddings = model_output.last_hidden_state  # (batch_size, seq_len, hidden_size)\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size())\n",
        "        return torch.sum(token_embeddings * input_mask_expanded, dim=1) / input_mask_expanded.sum(dim=1)\n",
        "\n",
        "    # Encode the query\n",
        "    query_tokens = tokenizer(query, return_tensors='pt', padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        query_output = model(**query_tokens)\n",
        "        query_embedding = mean_pooling(query_output, query_tokens['attention_mask'])\n",
        "\n",
        "    # Encode the passages\n",
        "    passage_embeddings = []\n",
        "    for passage in passages:\n",
        "        passage_tokens = tokenizer(passage, return_tensors='pt', padding=True, truncation=True)\n",
        "        with torch.no_grad():\n",
        "            passage_output = model(**passage_tokens)\n",
        "            passage_embedding = mean_pooling(passage_output, passage_tokens['attention_mask'])\n",
        "        passage_embeddings.append(passage_embedding)\n",
        "\n",
        "    # Convert embeddings to a single tensor\n",
        "    passage_embeddings = torch.cat(passage_embeddings, dim=0)\n",
        "\n",
        "    # Compute Euclidean distances\n",
        "    query_embedding_np = query_embedding.numpy()\n",
        "    passage_embeddings_np = passage_embeddings.numpy()\n",
        "    distances = np.linalg.norm(passage_embeddings_np - query_embedding_np, axis=1)\n",
        "\n",
        "    # Sort by ascending distances (smaller distance = more similar)\n",
        "    ranked_indices = distances.argsort()\n",
        "    return ranked_indices.tolist()\n"
      ],
      "metadata": {
        "id": "fizy5IMRA2XC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranked_indices_bert_Euclidean = rank_passages_bert_Euclidean(df.iloc[0][\"query\"], df.iloc[0][\"passage_text\"])"
      ],
      "metadata": {
        "id": "POlOLHS1A8Eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Ranked Indices of bert with Euclidean:\", ranked_indices_bert_Euclidean)"
      ],
      "metadata": {
        "id": "LluEvSjwA8Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"rank_passages_bert_Euclidean\"] = df.apply(lambda x: rank_passages_bert_Euclidean(x[\"query\"], x[\"passage_text\"]), axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "FLQKxlozBMHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result4 = evaluate_metrics(df, relevance_col='is_selected', rank_col='rank_passages_bert_Euclidean')\n",
        "result4"
      ],
      "metadata": {
        "id": "pQMzSOJcBMZL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMWf8rjVHt6w7RRoyGUwDvl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}